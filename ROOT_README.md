# Enhancing REST API Testing with NLP Techniques

Within this repository you will find the necessary components to run NLP2REST, our approach to automatically enhance OpenAPI specifications with rules (e.g, constraints and example values) extracted from natural language description fields.

Moreover, all the components required to replicate the experiment in our paper are provided (testing tools, benchmark APIs, etc.).

Summary of the steps that have to be followed to use our tool:
1. execution of target REST APIs (or public online APIs can be used);
2. deployment of Rule Extractor service (with Docker or locally);
3. execution of Rule Validator to validate rules and produce enhanced specification;

## 1. REST API(s)
The approach has to be run on one or more target REST APIs. The APIs must be reachable at the URLs specified in their OpenAPI specifications.

Users can either run one or more of the REST APIs we provide in this artifact (see the `services` directory), or they can resort to public APIs reachable on the internet. In the latter case, the only requirement is the availability of API's OpenAPI specifications.

To quickly test the approach, we suggest using the [FDIC REST API](https://banks.data.fdic.gov/) which is an online API (no deployment required), and we provide its specification in the `specifications` directory.

A more complex API to use is the [Spotify Web API](https://developer.spotify.com/documentation/web-api), however, authentication must be configured for this API. Moreover, we suggest not using personal Spotify accounts (but brand new, empty accounts), because the use of our tools might clear user's playlists and information. Spotify's OpenAPI specification is available in the `specifications` directory.


## 2. Deployment of the Rule Extractor service
The Rule Extractor service is a python application (reachable through a REST API) capable of extracting OpenAPI formal rules (e.g., constraints and example values) from natural language. To run the Rule Extractor please follow the instructions in the `rule_extractor` directory of this repository. In short, you will have to:
- get a model (either by training it, or by downloading the pre-trained model from the Google Drive link in the README file);
- build and run the python application (we provide a `Dockerfile` to quickly deploy the service, but instructions are also available to install the service on your system)
- the service is expected to run in the `localhost` on port `4000`, i.e., [http://localhost:4000/]()

## 3. Run the Rule Validator (custom strategy of RestTestGen)
The Rule Validator is a custom strategy built on top of RestTestGen framework, available in the `rule_validator` directory, that will:
1. parse the OpenAPI specification of the selected API (you need to provide the path to the specification in the configuration file of RestTestGen);
2. call the Rule Extractor service to extract rules from natural language descriptions;
3. interact with the target API to validate the extracted rules.

Please follow the instructions in the RestTestGen README.md file in the `rule_validator` directory to set up and run RestTestGen with the rule validation strategy.

The output of RestTestGen will be available in directory named `output`, and, specifically, in a subfolder of this directory named with the same name of the input specification, concatenated with a timestamp (e.g., `output/fdic-202305251554443`). This folder will contain the enhanced OpenAPI specification and reports of the HTTP interactions generated by the Rule Validator.

Please note that RestTestGen expects the Rule Extractor to be running at [http://localhost:4000/](). If you are running the Rule Extractor on a different port or host, please update the `baseUrl` field in the `RuleExtractorProxy` class of RestTestGen.

## 4. Experiment replication
The experiment presented in the paper consists in the comparison 

[FINISH]